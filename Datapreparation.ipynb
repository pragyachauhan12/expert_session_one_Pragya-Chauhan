{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a5ce61",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "### In this notebook we are going to prepare our data for our search function to use.\n",
    "### Currently our data is stored in two different csv files: 1: Order1.csv 2: Order_cost.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c43f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the important modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc1df2",
   "metadata": {},
   "source": [
    "# Define paths to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e37e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_Order_details   = f\"{getcwd()}/dataSet/Order11.csv\"\n",
    "PATH_Profit  = f\"{getcwd()}/dataSet/Order_cost21.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6726f6e",
   "metadata": {},
   "source": [
    "# Data Engineering\n",
    "###  Get data in dataframes\n",
    "###  Convert data into single dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da33e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['Region', 'Country', 'Item Type', 'Order Date', 'Order ID', 'Ship Date', 'Index']\n"
     ]
    }
   ],
   "source": [
    "'''Read from csv file order1'''\n",
    "order_details=pd.read_csv('order11.csv')\n",
    "details_columns = order_details.columns.tolist()\n",
    "print(f\"COLUMNS : {details_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f519240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['Order ID', 'Item Type', 'NoOfUnits', 'Unit Price', 'Total Cost']\n"
     ]
    }
   ],
   "source": [
    "'''Read from csv file order1'''\n",
    "order_cost=pd.read_csv('Order_cost21.csv')\n",
    "\n",
    "cost_columns = order_cost.columns.tolist()\n",
    "print(f\"COLUMNS : {cost_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b71bd2",
   "metadata": {},
   "source": [
    "### order ID is common in both the files so we're gonna use it as primary search key.\n",
    "###  A user will always search its order details by their Order ID so we will create a Global secondary index to be able to perform search our datastore.\n",
    "### In addition, It will make our searching faster and efficient so it's a good deal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e767aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is True  that the column 'Order ID' has unique values for all entries in order_details dataframe.\n",
      "It is True  that the column 'Order Id' has unique values for all entries in order_cost dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(f\"It is {pd.Series(order_details['Order ID']).is_unique}  that the column 'Order ID' has unique values for all entries in order_details dataframe.\")\n",
    "print(f\"It is {pd.Series(order_cost['Order ID']).is_unique}  that the column 'Order Id' has unique values for all entries in order_cost dataframe.\")\n",
    "\n",
    "# Sort order_details dataframe on the basis of Order ID as Order ID is unique for all entries..\n",
    "order_details_sorted = order_details.sort_values(by=['Order ID'])\n",
    "\n",
    "# Sort order_cost dataframe on the basis ofOrder ID as Order ID is unique for all entries..\n",
    "order_cost_sorted = order_cost.sort_values(by=['Order ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dfe5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from order_details dataframe...\n",
    "Order_ID    = order_details_sorted[\"Order ID\"].tolist()\n",
    "Region =order_details_sorted[\"Region\"].tolist()\n",
    "Country = order_details_sorted[\"Country\"].tolist()\n",
    "Item_type=order_details_sorted[\"Item Type\"].tolist()\n",
    "Order_date=order_details_sorted[\"Order Date\"].tolist()\n",
    "Ship_date=order_details_sorted[\"Ship Date\"].tolist()\n",
    "# from order_cost dataframe...\n",
    "\n",
    "Number=order_cost_sorted[\"NoOfUnits\"].tolist()\n",
    "Unit_price=order_cost_sorted[\"Unit Price\"].tolist()\n",
    "Total_cost=order_cost_sorted[\"Total Cost\"].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b14ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now we here we have created two dictionary and a list'''\n",
    "detailslist           = []\n",
    "detailsdict={}\n",
    "global_secondaryIndex = {}\n",
    "for idx,OID  in enumerate(Order_ID):\n",
    "    \n",
    "       detailslist.append(OID)\n",
    "#    append function of list to add elements.\n",
    "\n",
    "       detailsdict[OID]={\n",
    "       \"Order_ID\":Order_ID[idx],\n",
    "       \"Region\" :Region[idx],\n",
    "       \"Country\" :Country[idx],\n",
    "       \"Itemtype\":Item_type[idx],\n",
    "       \"Orderdate\":Order_date[idx],\n",
    "       \"Shipdate\":Ship_date[idx],\n",
    "          \"costs\":{ \n",
    "            \"Number\" : Number[idx],\n",
    "            \"Price\": Unit_price[idx],\n",
    "            \"Totalcost\":Total_cost[idx]\n",
    "    \n",
    "          }}\n",
    "    \n",
    "       global_secondaryIndex[idx]=Order_ID[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e54f7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables which are no longer in use while holding large amount of data.\n",
    "del Order_ID\n",
    "del Region\n",
    "del Country\n",
    "del Item_type\n",
    "del Order_date\n",
    "del Ship_date\n",
    "\n",
    "del Number\n",
    "del Unit_price\n",
    "del Total_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99759f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Writing movie Data into the disk...\n",
      "[INFO] Writing Global Secondary Index Data into the disk...\n"
     ]
    }
   ],
   "source": [
    "#here we are creating two json files newdataFinal_GIS.json and Order_cost1.csv using two dictionary global_secondaryIndex and detailsdict respectively.\n",
    "import json\n",
    "print(\"[INFO] Writing movie Data into the disk...\")\n",
    "with open('Order_cost1.json', 'w') as fp:\n",
    "    json.dump(detailsdict, fp, sort_keys=True, indent=4)\n",
    "print(\"[INFO] Writing Global Secondary Index Data into the disk...\")\n",
    "with open('newdataFinal_GIS.json', 'w') as fp:\n",
    "    json.dump(global_secondaryIndex, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424ce27",
   "metadata": {},
   "source": [
    "### At this point, our database is ready and it can handel high inflow of requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c869df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
